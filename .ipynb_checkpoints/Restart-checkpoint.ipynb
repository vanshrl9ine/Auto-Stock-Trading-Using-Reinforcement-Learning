{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc709d59-3ab6-401e-a803-4ff31993ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "\n",
    "from finrl import config\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfed73f-b71d-450e-8532-471fc33abde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_symbols = [\n",
    "#     'ADANIENT', 'ADANIPORTS', 'APOLLOHOSP', 'ASIANPAINT', 'AXISBANK',\n",
    "#     'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BPCL', 'BHARTIARTL',\n",
    "#     'BRITANNIA', 'CIPLA', 'COALINDIA', 'DIVISLAB', 'DRREDDY', 'EICHERMOT',\n",
    "#     'GRASIM', 'HCLTECH', 'HDFCBANK', 'HDFCLIFE', 'HEROMOTOCO', 'HINDALCO',\n",
    "#     'HINDUNILVR', 'ICICIBANK', 'INDUSINDBK', 'INFY', 'ITC', 'JSWSTEEL',\n",
    "#     'KOTAKBANK', 'LT', 'LTIM', 'M&M', 'MARUTI', 'NESTLEIND', 'NTPC', 'ONGC',\n",
    "#     'POWERGRID', 'RELIANCE', 'SBILIFE', 'SBIN', 'SUNPHARMA', 'TATAMOTORS',\n",
    "#     'TATASTEEL', 'TCS', 'TATACONSUM', 'TECHM', 'TITAN', 'ULTRACEMCO', 'UPL',\n",
    "#     'WIPRO'\n",
    "# ]\n",
    "\n",
    "# ns_company_symbols = [symbol + '.NS' for symbol in company_symbols]\n",
    "\n",
    "# print(ns_company_symbols)\n",
    "# symbols=ns_company_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09ec60f-d1f4-4b21-97a6-60fe0c7cc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2020-07-01'\n",
    "TRADE_START_DATE = '2020-07-01'\n",
    "TRADE_END_DATE = '2023-05-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70746a8e-df0e-49b5-a146-21dab4e23a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "#                                 end_date = TRADE_END_DATE,\n",
    "#                                 ticker_list = symbols).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b33b42-1022-48ba-9bb4-724b1fa70c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_csv('datasets/BSE30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5e44b-1124-4426-87de-925b8c8fff98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19eecd6d-8e85-4f7e-a6b3-542e23cab110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105703 entries, 0 to 105702\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    105703 non-null  object \n",
      " 1   open    105703 non-null  float64\n",
      " 2   high    105703 non-null  float64\n",
      " 3   low     105703 non-null  float64\n",
      " 4   close   105703 non-null  float64\n",
      " 5   volume  105703 non-null  int64  \n",
      " 6   tic     105703 non-null  object \n",
      " 7   day     105703 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9b1894-7f81-4c66-958f-2932b8cc5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(*, file_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    load csv dataset from path\n",
    "    :return: (df) pandas dataframe\n",
    "    \"\"\"\n",
    "    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n",
    "    _data = pd.read_csv(file_name)\n",
    "    return _data\n",
    "\n",
    "\n",
    "def data_split(df, start, end, target_date_col=\"date\"):\n",
    "    \"\"\"\n",
    "    split the dataset into training or testing using date\n",
    "    :param data: (df) pandas dataframe, start, end\n",
    "    :return: (df) pandas dataframe\n",
    "    \"\"\"\n",
    "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
    "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
    "    data.index = data[target_date_col].factorize()[0]\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_to_datetime(time):\n",
    "    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n",
    "    if isinstance(time, str):\n",
    "        return datetime.datetime.strptime(time, time_fmt)\n",
    "\n",
    "\n",
    "class FeatureEngineer:\n",
    "    \"\"\"Provides methods for preprocessing the stock price data\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        use_technical_indicator : boolean\n",
    "            we technical indicator or not\n",
    "        tech_indicator_list : list\n",
    "            a list of technical indicator names (modified from neofinrl_config.py)\n",
    "        use_turbulence : boolean\n",
    "            use turbulence index or not\n",
    "        user_defined_feature:boolean\n",
    "            use user defined features or not\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess_data()\n",
    "        main method to do the feature engineering\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_technical_indicator=True,\n",
    "        tech_indicator_list=config.INDICATORS,\n",
    "        use_vix=False,\n",
    "        use_turbulence=False,\n",
    "        user_defined_feature=False,\n",
    "    ):\n",
    "        self.use_technical_indicator = use_technical_indicator\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.use_vix = use_vix\n",
    "        self.use_turbulence = use_turbulence\n",
    "        self.user_defined_feature = user_defined_feature\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"main method to do the feature engineering\n",
    "        @:param config: source dataframe\n",
    "        @:return: a DataMatrices object\n",
    "        \"\"\"\n",
    "        # clean data\n",
    "        df = self.clean_data(df)\n",
    "\n",
    "        # add technical indicators using stockstats\n",
    "        if self.use_technical_indicator:\n",
    "            df = self.add_technical_indicator(df)\n",
    "            print(\"Successfully added technical indicators\")\n",
    "\n",
    "        # add vix for multiple stock\n",
    "        if self.use_vix:\n",
    "            df = self.add_vix(df)\n",
    "            print(\"Successfully added vix\")\n",
    "\n",
    "        # add turbulence index for multiple stock\n",
    "        if self.use_turbulence:\n",
    "            df = self.add_turbulence(df)\n",
    "            print(\"Successfully added turbulence index\")\n",
    "\n",
    "        # add user defined feature\n",
    "        if self.user_defined_feature:\n",
    "            df = self.add_user_defined_feature(df)\n",
    "            print(\"Successfully added user defined features\")\n",
    "\n",
    "        # fill the missing values at the beginning and the end\n",
    "        df = df.ffill().bfill()\n",
    "        return df\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        \"\"\"\n",
    "        clean the raw data\n",
    "        deal with missing values\n",
    "        reasons: stocks could be delisted, not incorporated at the time step\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "        df.index = df.date.factorize()[0]\n",
    "        merged_closes = df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        merged_closes = merged_closes.fillna(merged_closes.mean())\n",
    "        # merged_closes = merged_closes.fillna(merged_closes.mean())\n",
    "        tics = merged_closes.columns\n",
    "        df = df[df.tic.isin(tics)]\n",
    "        \n",
    "        # df = data.copy()\n",
    "        # list_ticker = df[\"tic\"].unique().tolist()\n",
    "        # # only apply to daily level data, need to fix for minute level\n",
    "        # list_date = list(pd.date_range(df['date'].min(),df['date'].max()).astype(str))\n",
    "        # combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "        # df_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n",
    "        # df_full = df_full[df_full['date'].isin(df['date'])]\n",
    "        # df_full = df_full.sort_values(['date','tic'])\n",
    "        # df_full = df_full.fillna(0)\n",
    "        return df\n",
    "\n",
    "    def add_technical_indicator(self, data):\n",
    "        \"\"\"\n",
    "        calculate technical indicators\n",
    "        use stockstats package to add technical inidactors\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df = df.sort_values(by=[\"tic\", \"date\"])\n",
    "        stock = Sdf.retype(df.copy())\n",
    "        unique_ticker = stock.tic.unique()\n",
    "\n",
    "        for indicator in self.tech_indicator_list:\n",
    "            indicator_df = pd.DataFrame()\n",
    "            for i in range(len(unique_ticker)):\n",
    "                try:\n",
    "                    temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n",
    "                    temp_indicator = pd.DataFrame(temp_indicator)\n",
    "                    temp_indicator[\"tic\"] = unique_ticker[i]\n",
    "                    temp_indicator[\"date\"] = df[df.tic == unique_ticker[i]][\n",
    "                        \"date\"\n",
    "                    ].to_list()\n",
    "                    # indicator_df = indicator_df.append(\n",
    "                    #     temp_indicator, ignore_index=True\n",
    "                    # )\n",
    "                    indicator_df = pd.concat(\n",
    "                        [indicator_df, temp_indicator], axis=0, ignore_index=True\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            df = df.merge(\n",
    "                indicator_df[[\"tic\", \"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n",
    "            )\n",
    "        df = df.sort_values(by=[\"date\", \"tic\"])\n",
    "        return df\n",
    "        # df = data.set_index(['date','tic']).sort_index()\n",
    "        # df = df.join(df.groupby(level=0, group_keys=False).apply(lambda x, y: Sdf.retype(x)[y], y=self.tech_indicator_list))\n",
    "        # return df.reset_index()\n",
    "\n",
    "    def add_user_defined_feature(self, data):\n",
    "        \"\"\"\n",
    "         add user defined features\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df[\"daily_return\"] = df.close.pct_change(1)\n",
    "        # df['return_lag_1']=df.close.pct_change(2)\n",
    "        # df['return_lag_2']=df.close.pct_change(3)\n",
    "        # df['return_lag_3']=df.close.pct_change(4)\n",
    "        # df['return_lag_4']=df.close.pct_change(5)\n",
    "        return df\n",
    "\n",
    "    def add_vix(self, data):\n",
    "        \"\"\"\n",
    "        add vix from yahoo finance\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df_vix = YahooDownloader(\n",
    "            start_date=df.date.min(), end_date=df.date.max(), ticker_list=[\"^VIX\"]\n",
    "        ).fetch_data()\n",
    "        vix = df_vix[[\"date\", \"close\"]]\n",
    "        vix.columns = [\"date\", \"vix\"]\n",
    "\n",
    "        df = df.merge(vix, on=\"date\")\n",
    "        df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def add_turbulence(self, data):\n",
    "        \"\"\"\n",
    "        add turbulence index from a precalcualted dataframe\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        turbulence_index = self.calculate_turbulence(df)\n",
    "        df = df.merge(turbulence_index, on=\"date\")\n",
    "        df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def calculate_turbulence(self, data):\n",
    "        \"\"\"calculate turbulence index based on dow 30\"\"\"\n",
    "        # can add other market assets\n",
    "        df = data.copy()\n",
    "        df_price_pivot = df.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        # use returns to calculate turbulence\n",
    "        df_price_pivot = df_price_pivot.pct_change()\n",
    "\n",
    "        unique_date = df.date.unique()\n",
    "        # start after a year\n",
    "        start = 252\n",
    "        turbulence_index = [0] * start\n",
    "        # turbulence_index = [0]\n",
    "        count = 0\n",
    "        for i in range(start, len(unique_date)):\n",
    "            current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
    "            # use one year rolling window to calcualte covariance\n",
    "            hist_price = df_price_pivot[\n",
    "                (df_price_pivot.index < unique_date[i])\n",
    "                & (df_price_pivot.index >= unique_date[i - 252])\n",
    "            ]\n",
    "            # Drop tickers which has number missing values more than the \"oldest\" ticker\n",
    "            filtered_hist_price = hist_price.iloc[\n",
    "                hist_price.isna().sum().min() :\n",
    "            ].dropna(axis=1)\n",
    "\n",
    "            cov_temp = filtered_hist_price.cov()\n",
    "            current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(\n",
    "                filtered_hist_price, axis=0\n",
    "            )\n",
    "            # cov_temp = hist_price.cov()\n",
    "            # current_temp=(current_price - np.mean(hist_price,axis=0))\n",
    "\n",
    "            temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(\n",
    "                current_temp.values.T\n",
    "            )\n",
    "            if temp > 0:\n",
    "                count += 1\n",
    "                if count > 2:\n",
    "                    turbulence_temp = temp[0][0]\n",
    "                else:\n",
    "                    # avoid large outlier because of the calculation just begins\n",
    "                    turbulence_temp = 0\n",
    "            else:\n",
    "                turbulence_temp = 0\n",
    "            turbulence_index.append(turbulence_temp)\n",
    "        try:\n",
    "            turbulence_index = pd.DataFrame(\n",
    "                {\"date\": df_price_pivot.index, \"turbulence\": turbulence_index}\n",
    "            )\n",
    "        except ValueError:\n",
    "            raise Exception(\"Turbulence information could not be added.\")\n",
    "        return turbulence_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638a5036-ce5b-45e4-be69-ef5f6a46da2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close   volume  \\\n",
       "0  2009-01-02   90.750000   90.750000   88.550003   48.861801    19140   \n",
       "1  2009-01-02  105.800003  109.599998  103.459999   71.914917  4536215   \n",
       "2  2009-01-02  206.050003  210.500000  196.500000  158.413025    52648   \n",
       "3  2009-01-02   15.140000   15.800000   14.975000   13.401811   136590   \n",
       "4  2009-01-02    6.660000    6.970000    6.350000    2.746401   274220   \n",
       "\n",
       "             tic  day  \n",
       "0  ASIANPAINT.BO    4  \n",
       "1    AXISBANK.BO    4  \n",
       "2  BAJAJ-AUTO.BO    4  \n",
       "3  BAJAJFINSV.BO    4  \n",
       "4  BAJFINANCE.BO    4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febd40c0-9d74-44a1-9fcf-a3b6f7b7bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vansh\\AppData\\Local\\Temp\\ipykernel_15508\\50613336.py:222: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_price_pivot = df_price_pivot.pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "from finrl.config import INDICATORS\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                      tech_indicator_list = INDICATORS,\n",
    "                      use_vix=False,\n",
    "                      use_turbulence=True,\n",
    "                      user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083563ce-5668-49e3-abed-4c42a4bfa9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105698</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>992.500000</td>\n",
       "      <td>979.250000</td>\n",
       "      <td>986.799988</td>\n",
       "      <td>26056</td>\n",
       "      <td>SUNPHARMA.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.263414</td>\n",
       "      <td>1019.314408</td>\n",
       "      <td>965.265603</td>\n",
       "      <td>50.085294</td>\n",
       "      <td>14.481255</td>\n",
       "      <td>1.567920</td>\n",
       "      <td>983.446670</td>\n",
       "      <td>985.046100</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105699</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3227.199951</td>\n",
       "      <td>3197.149902</td>\n",
       "      <td>3175.769043</td>\n",
       "      <td>51644</td>\n",
       "      <td>TCS.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>-15.398183</td>\n",
       "      <td>3235.633708</td>\n",
       "      <td>3045.249324</td>\n",
       "      <td>48.649310</td>\n",
       "      <td>67.966063</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>3131.238102</td>\n",
       "      <td>3257.234477</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105700</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>1026.650024</td>\n",
       "      <td>982.950012</td>\n",
       "      <td>986.955139</td>\n",
       "      <td>279514</td>\n",
       "      <td>TECHM.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>-22.941437</td>\n",
       "      <td>1102.074200</td>\n",
       "      <td>929.293964</td>\n",
       "      <td>44.970681</td>\n",
       "      <td>-99.119890</td>\n",
       "      <td>22.233939</td>\n",
       "      <td>1033.226742</td>\n",
       "      <td>1032.633037</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105701</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>2679.300049</td>\n",
       "      <td>2620.050049</td>\n",
       "      <td>2640.399902</td>\n",
       "      <td>32742</td>\n",
       "      <td>TITAN.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>43.161331</td>\n",
       "      <td>2669.834479</td>\n",
       "      <td>2492.325506</td>\n",
       "      <td>60.306098</td>\n",
       "      <td>116.653875</td>\n",
       "      <td>37.463255</td>\n",
       "      <td>2542.391650</td>\n",
       "      <td>2482.099988</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105702</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>7524.950195</td>\n",
       "      <td>7576.549805</td>\n",
       "      <td>7487.549805</td>\n",
       "      <td>7520.226562</td>\n",
       "      <td>8316</td>\n",
       "      <td>ULTRACEMCO.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>28.692164</td>\n",
       "      <td>7774.630825</td>\n",
       "      <td>7303.703648</td>\n",
       "      <td>55.649892</td>\n",
       "      <td>27.765845</td>\n",
       "      <td>3.677975</td>\n",
       "      <td>7441.862826</td>\n",
       "      <td>7301.539185</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105703 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date         open         high          low        close  \\\n",
       "0       2009-01-02    90.750000    90.750000    88.550003    48.861801   \n",
       "1       2009-01-02   105.800003   109.599998   103.459999    71.914917   \n",
       "2       2009-01-02   206.050003   210.500000   196.500000   158.413025   \n",
       "3       2009-01-02    15.140000    15.800000    14.975000    13.401811   \n",
       "4       2009-01-02     6.660000     6.970000     6.350000     2.746401   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "105698  2023-04-28   981.000000   992.500000   979.250000   986.799988   \n",
       "105699  2023-04-28  3208.000000  3227.199951  3197.149902  3175.769043   \n",
       "105700  2023-04-28   983.000000  1026.650024   982.950012   986.955139   \n",
       "105701  2023-04-28  2663.500000  2679.300049  2620.050049  2640.399902   \n",
       "105702  2023-04-28  7524.950195  7576.549805  7487.549805  7520.226562   \n",
       "\n",
       "         volume            tic  day       macd      boll_ub      boll_lb  \\\n",
       "0         19140  ASIANPAINT.BO    4   0.000000    50.523346    48.068260   \n",
       "1       4536215    AXISBANK.BO    4   0.000000    50.523346    48.068260   \n",
       "2         52648  BAJAJ-AUTO.BO    4   0.000000    50.523346    48.068260   \n",
       "3        136590  BAJAJFINSV.BO    4   0.000000    50.523346    48.068260   \n",
       "4        274220  BAJFINANCE.BO    4   0.000000    50.523346    48.068260   \n",
       "...         ...            ...  ...        ...          ...          ...   \n",
       "105698    26056   SUNPHARMA.BO    4  -0.263414  1019.314408   965.265603   \n",
       "105699    51644         TCS.BO    4 -15.398183  3235.633708  3045.249324   \n",
       "105700   279514       TECHM.BO    4 -22.941437  1102.074200   929.293964   \n",
       "105701    32742       TITAN.BO    4  43.161331  2669.834479  2492.325506   \n",
       "105702     8316  ULTRACEMCO.BO    4  28.692164  7774.630825  7303.703648   \n",
       "\n",
       "            rsi_30      cci_30       dx_30  close_30_sma  close_60_sma  \\\n",
       "0       100.000000   66.666667  100.000000     48.861801     48.861801   \n",
       "1       100.000000   66.666667  100.000000     71.914917     71.914917   \n",
       "2       100.000000   66.666667  100.000000    158.413025    158.413025   \n",
       "3       100.000000   66.666667  100.000000     13.401811     13.401811   \n",
       "4       100.000000   66.666667  100.000000      2.746401      2.746401   \n",
       "...            ...         ...         ...           ...           ...   \n",
       "105698   50.085294   14.481255    1.567920    983.446670    985.046100   \n",
       "105699   48.649310   67.966063    0.407494   3131.238102   3257.234477   \n",
       "105700   44.970681  -99.119890   22.233939   1033.226742   1032.633037   \n",
       "105701   60.306098  116.653875   37.463255   2542.391650   2482.099988   \n",
       "105702   55.649892   27.765845    3.677975   7441.862826   7301.539185   \n",
       "\n",
       "        turbulence  \n",
       "0         0.000000  \n",
       "1         0.000000  \n",
       "2         0.000000  \n",
       "3         0.000000  \n",
       "4         0.000000  \n",
       "...            ...  \n",
       "105698   43.069415  \n",
       "105699   43.069415  \n",
       "105700   43.069415  \n",
       "105701   43.069415  \n",
       "105702   43.069415  \n",
       "\n",
       "[105703 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b299a545-307a-4d24-a530-9c7a1e0e84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b45789e-5f8a-4a0d-a1ba-070d4601b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = df[\"tic\"].unique().tolist()\n",
    "# only apply to daily level data, need to fix for minute level\n",
    "list_date = list(pd.date_range(df['date'].min(),df['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "df_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n",
    "df_full = df_full[df_full['date'].isin(df['date'])]\n",
    "df_full = df_full.sort_values(['date','tic'])\n",
    "df_full = df_full.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe4ccb1a-fe6a-41e1-95fe-8a3363465c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 105900 entries, 0 to 156899\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   date          105900 non-null  object \n",
      " 1   tic           105900 non-null  object \n",
      " 2   open          105900 non-null  float64\n",
      " 3   high          105900 non-null  float64\n",
      " 4   low           105900 non-null  float64\n",
      " 5   close         105900 non-null  float64\n",
      " 6   volume        105900 non-null  float64\n",
      " 7   day           105900 non-null  float64\n",
      " 8   macd          105900 non-null  float64\n",
      " 9   boll_ub       105900 non-null  float64\n",
      " 10  boll_lb       105900 non-null  float64\n",
      " 11  rsi_30        105900 non-null  float64\n",
      " 12  cci_30        105900 non-null  float64\n",
      " 13  dx_30         105900 non-null  float64\n",
      " 14  close_30_sma  105900 non-null  float64\n",
      " 15  close_60_sma  105900 non-null  float64\n",
      " 16  turbulence    105900 non-null  float64\n",
      "dtypes: float64(15), object(2)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f2577b7-eabd-4f2c-a467-cb5584c94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05041644-b750-457e-81c5-29c56fc1d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            tic        open        high         low       close  \\\n",
       "0  2009-01-02  ASIANPAINT.BO   90.750000   90.750000   88.550003   48.861801   \n",
       "1  2009-01-02    AXISBANK.BO  105.800003  109.599998  103.459999   71.914917   \n",
       "2  2009-01-02  BAJAJ-AUTO.BO  206.050003  210.500000  196.500000  158.413025   \n",
       "3  2009-01-02  BAJAJFINSV.BO   15.140000   15.800000   14.975000   13.401811   \n",
       "4  2009-01-02  BAJFINANCE.BO    6.660000    6.970000    6.350000    2.746401   \n",
       "\n",
       "      volume  day  macd    boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0    19140.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "1  4536215.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "2    52648.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "3   136590.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "4   274220.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma  turbulence  \n",
       "0     48.861801     48.861801         0.0  \n",
       "1     71.914917     71.914917         0.0  \n",
       "2    158.413025    158.413025         0.0  \n",
       "3     13.401811     13.401811         0.0  \n",
       "4      2.746401      2.746401         0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067ab770-a250-4ae6-9192-79a47e011ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105900, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393cca95-93e7-4b32-ab39-f8d91e2dff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"main_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d693281c-6f61-4e7a-8e54-d7fb8078750b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            tic        open        high         low       close  \\\n",
       "0  2009-01-02  ASIANPAINT.BO   90.750000   90.750000   88.550003   48.861801   \n",
       "1  2009-01-02    AXISBANK.BO  105.800003  109.599998  103.459999   71.914917   \n",
       "2  2009-01-02  BAJAJ-AUTO.BO  206.050003  210.500000  196.500000  158.413025   \n",
       "3  2009-01-02  BAJAJFINSV.BO   15.140000   15.800000   14.975000   13.401811   \n",
       "4  2009-01-02  BAJFINANCE.BO    6.660000    6.970000    6.350000    2.746401   \n",
       "\n",
       "      volume  day  macd    boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0    19140.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "1  4536215.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "2    52648.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "3   136590.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "4   274220.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma  turbulence  \n",
       "0     48.861801     48.861801         0.0  \n",
       "1     71.914917     71.914917         0.0  \n",
       "2    158.413025    158.413025         0.0  \n",
       "3     13.401811     13.401811         0.0  \n",
       "4      2.746401      2.746401         0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e7b88a-c11e-445c-a013-28994505acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d8ef628-f80f-4d6d-9a2f-b626ad01064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        stock_dim,\n",
    "        hmax,\n",
    "        initial_amount,\n",
    "        buy_cost_pct,\n",
    "        sell_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        tech_indicator_list,\n",
    "        turbulence_threshold=None,\n",
    "        make_plots=False,\n",
    "        print_verbosity=2,\n",
    "        day=0,\n",
    "        initial=True,\n",
    "        previous_state=[],\n",
    "        model_name=\"\",\n",
    "        mode=\"\",\n",
    "        iteration=\"\",\n",
    "        initial_buy=False,  # Use half of initial amount to buy\n",
    "        hundred_each_trade=True,  # The number of shares per lot must be an integer multiple of 100\n",
    "    ):\n",
    "        self.day = day\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
    "        )\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.terminal = False\n",
    "        self.make_plots = make_plots\n",
    "        self.print_verbosity = print_verbosity\n",
    "        self.turbulence_threshold = turbulence_threshold\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        self.model_name = model_name\n",
    "        self.mode = mode\n",
    "        self.iteration = iteration\n",
    "        # initalize state\n",
    "        self.initial_buy = initial_buy\n",
    "        self.hundred_each_trade = hundred_each_trade\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.episode = 0\n",
    "        # memorize all the total balance change\n",
    "        self.portfolio_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        self._seed()\n",
    "\n",
    "    def _sell_stock(self, index, action):\n",
    "        def _do_sell_normal():\n",
    "            if self.state[index + 1] > 0:\n",
    "                # Sell only if the price is > 0 (no missing data in this particular date)\n",
    "                # perform sell action based on the sign of the action\n",
    "                if self.state[index + self.stock_dim + 1] > 0:\n",
    "                    # Sell only if current asset is > 0\n",
    "                    sell_num_shares = min(\n",
    "                        abs(action), self.state[index + self.stock_dim + 1]\n",
    "                    )\n",
    "                    if self.hundred_each_trade:\n",
    "                        sell_num_shares = sell_num_shares // 100 * 100\n",
    "\n",
    "                    sell_amount = self.state[index + 1] * sell_num_shares\n",
    "                    cost_amount = sell_amount * self.sell_cost_pct\n",
    "                    self.state[0] += sell_amount - cost_amount\n",
    "                    self.state[index + self.stock_dim + 1] -= sell_num_shares\n",
    "                    self.cost += cost_amount\n",
    "                    self.trades += 1\n",
    "                else:\n",
    "                    sell_num_shares = 0\n",
    "            else:\n",
    "                sell_num_shares = 0\n",
    "\n",
    "            return sell_num_shares\n",
    "\n",
    "        # perform sell action based on the sign of the action\n",
    "        if self.turbulence_threshold is not None:\n",
    "            if self.turbulence >= self.turbulence_threshold:\n",
    "                if self.state[index + 1] > 0:\n",
    "                    # Sell only if the price is > 0 (no missing data in this particular date)\n",
    "                    # if turbulence goes over threshold, just clear out all positions\n",
    "                    if self.state[index + self.stock_dim + 1] > 0:\n",
    "                        # Sell only if current asset is > 0\n",
    "                        sell_num_shares = self.state[index + self.stock_dim + 1]\n",
    "                        sell_amount = self.state[index + 1] * sell_num_shares\n",
    "                        cost_amount = sell_amount * self.sell_cost_pct\n",
    "\n",
    "                        self.state[0] += sell_amount - cost_amount\n",
    "\n",
    "                        self.state[index + self.stock_dim + 1] = 0\n",
    "                        self.cost += cost_amount\n",
    "                        self.trades += 1\n",
    "                    else:\n",
    "                        sell_num_shares = 0\n",
    "                else:\n",
    "                    sell_num_shares = 0\n",
    "            else:\n",
    "                sell_num_shares = _do_sell_normal()\n",
    "        else:\n",
    "            sell_num_shares = _do_sell_normal()\n",
    "\n",
    "        return sell_num_shares\n",
    "\n",
    "    def _buy_stock(self, index, action):\n",
    "        def _do_buy():\n",
    "            if self.state[index + 1] > 0:\n",
    "                # Buy only if the price is > 0 (no missing data in this particular date)\n",
    "                available_amount = self.state[0] // self.state[index + 1]\n",
    "\n",
    "                # update balance\n",
    "                buy_num_shares = min(available_amount, action)\n",
    "                if self.hundred_each_trade:\n",
    "                    buy_num_shares = buy_num_shares // 100 * 100\n",
    "\n",
    "                if buy_num_shares > 0:\n",
    "                    buy_amount = self.state[index + 1] * buy_num_shares\n",
    "                    cost_amount = buy_amount * self.buy_cost_pct\n",
    "\n",
    "                    self.state[0] -= buy_amount + cost_amount\n",
    "\n",
    "                    self.state[index + self.stock_dim + 1] += buy_num_shares\n",
    "\n",
    "                    self.cost += cost_amount\n",
    "                    self.trades += 1\n",
    "                else:\n",
    "                    buy_num_shares = 0\n",
    "            else:\n",
    "                buy_num_shares = 0\n",
    "\n",
    "            return buy_num_shares\n",
    "\n",
    "        # perform buy action based on the sign of the action\n",
    "        if self.turbulence_threshold is None:\n",
    "            buy_num_shares = _do_buy()\n",
    "        else:\n",
    "            if self.turbulence < self.turbulence_threshold:\n",
    "                buy_num_shares = _do_buy()\n",
    "            else:\n",
    "                buy_num_shares = 0\n",
    "                pass\n",
    "\n",
    "        return buy_num_shares\n",
    "\n",
    "    def _make_plot(self):\n",
    "        portfolio_df = self.get_portfolio_df()\n",
    "        plt.plot(portfolio_df[\"date\"], portfolio_df[\"total_asset\"], color=\"r\")\n",
    "        plt.savefig(f\"results/account_value_trade_{self.episode}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "        if self.terminal:\n",
    "            print(f\"Episode: {self.episode}\")\n",
    "            if self.make_plots:\n",
    "                self._make_plot()\n",
    "\n",
    "            portfolio_df = self.get_portfolio_df()\n",
    "            begin_total_asset = portfolio_df[\"prev_total_asset\"].iloc[0]\n",
    "            end_total_asset = portfolio_df[\"total_asset\"].iloc[-1]\n",
    "            tot_reward = end_total_asset - begin_total_asset\n",
    "\n",
    "            portfolio_df[\"daily_return\"] = portfolio_df[\"total_asset\"].pct_change(1)\n",
    "\n",
    "            sharpe = None\n",
    "            if portfolio_df[\"daily_return\"].std() != 0:\n",
    "                sharpe = (\n",
    "                    (252**0.5)\n",
    "                    * portfolio_df[\"daily_return\"].mean()\n",
    "                    / portfolio_df[\"daily_return\"].std()\n",
    "                )\n",
    "\n",
    "            if self.episode % self.print_verbosity == 0:\n",
    "                print(f\"day: {self.day}, episode: {self.episode}\")\n",
    "                print(f\"begin_total_asset: {begin_total_asset:0.2f}\")\n",
    "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
    "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
    "                print(f\"total_cost: {self.cost:0.2f}\")\n",
    "                print(f\"total_trades: {self.trades}\")\n",
    "                if sharpe is not None:\n",
    "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
    "                print(\"=================================\")\n",
    "\n",
    "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
    "                df_actions = self.save_action_memory()\n",
    "                df_actions.to_csv(\n",
    "                    f\"results/actions_{self.mode}_{self.model_name}_{self.episode}.csv\"\n",
    "                )\n",
    "                portfolio_df.to_csv(\n",
    "                    f\"results/portfolio_{self.mode}_{self.model_name}_{self.episode}.csv\",\n",
    "                    index=False,\n",
    "                )\n",
    "\n",
    "            # Add outputs to logger interface\n",
    "            # logger.record(key=\"environment/portfolio_value\", value=end_total_asset)\n",
    "            # logger.record(key=\"environment/total_reward\", value=tot_reward)\n",
    "            # logger.record(key=\"environment/total_reward_pct\", value=(tot_reward / (end_total_asset - tot_reward)) * 100)\n",
    "            # logger.record(key=\"environment/total_cost\", value=self.cost)\n",
    "            # logger.record(key=\"environment/total_trades\", value=self.trades)\n",
    "\n",
    "            return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "        else:\n",
    "            actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
    "            actions = actions.astype(\n",
    "                int\n",
    "            )  # convert into integer because we can't by fraction of shares\n",
    "            if self.turbulence_threshold is not None:\n",
    "                if self.turbulence >= self.turbulence_threshold:\n",
    "                    actions = np.array([-self.hmax] * self.stock_dim)\n",
    "\n",
    "            # calculate information before trading\n",
    "            begin_cash = self.state[0]\n",
    "            begin_market_value = self._get_market_value()\n",
    "            begin_total_asset = begin_cash + begin_market_value\n",
    "            begin_cost = self.cost\n",
    "            begin_trades = self.trades\n",
    "            begin_stock = self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
    "\n",
    "            argsort_actions = np.argsort(actions)\n",
    "\n",
    "            sell_index = argsort_actions[: np.where(actions < 0)[0].shape[0]]\n",
    "            buy_index = argsort_actions[::-1][: np.where(actions > 0)[0].shape[0]]\n",
    "\n",
    "            for index in sell_index:\n",
    "                actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
    "\n",
    "            for index in buy_index:\n",
    "                actions[index] = self._buy_stock(index, actions[index])\n",
    "\n",
    "            if self.turbulence_threshold is not None:\n",
    "                self.turbulence = self.data[\"turbulence\"].values[0]\n",
    "\n",
    "            # calculate information after trading\n",
    "            end_cash = self.state[0]\n",
    "            end_market_value = self._get_market_value()\n",
    "            end_total_asset = end_cash + end_market_value\n",
    "            end_cost = self.cost\n",
    "            end_trades = self.trades\n",
    "            end_stock = self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
    "\n",
    "            self.actions_memory.append(actions)\n",
    "\n",
    "            i_list = []\n",
    "            for i in range(self.stock_dim):\n",
    "                if begin_stock[i] - end_stock[i] == 0:\n",
    "                    i_list.append(i)\n",
    "\n",
    "            self.reward = end_total_asset - begin_total_asset\n",
    "            for i in i_list:\n",
    "                self.reward -= (\n",
    "                    self.state[i + 1] * self.state[self.stock_dim + 1 + i]\n",
    "                ) * 0.001\n",
    "\n",
    "            date = self._get_date()\n",
    "\n",
    "            self.portfolio_memory.append(\n",
    "                {\n",
    "                    \"date\": date,\n",
    "                    \"prev_total_asset\": begin_total_asset,\n",
    "                    \"prev_cash\": begin_cash,\n",
    "                    \"prev_market_value\": begin_market_value,\n",
    "                    \"total_asset\": end_total_asset,\n",
    "                    \"cash\": end_cash,\n",
    "                    \"market_value\": end_market_value,\n",
    "                    \"cost\": end_cost - begin_cost,\n",
    "                    \"trades\": end_trades - begin_trades,\n",
    "                    \"reward\": self.reward,\n",
    "                }\n",
    "            )\n",
    "            self.date_memory.append(date)\n",
    "\n",
    "            self.reward = self.reward * self.reward_scaling\n",
    "\n",
    "            # update next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            self.state = self._update_state()\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # initiate state\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "\n",
    "        self.state = self._initiate_state()\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False\n",
    "        # self.iteration=self.iteration\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        self.portfolio_memory = []\n",
    "\n",
    "        self.episode += 1\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "    def _initiate_state(self):\n",
    "        if self.initial:\n",
    "            # For Initial State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + self.data.close.values.tolist()\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[tech].values.tolist()\n",
    "                            for tech in self.tech_indicator_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if self.initial_buy:\n",
    "                    state = self.initial_buy_()\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + [self.data.close]\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum(\n",
    "                        [[self.data[tech]] for tech in self.tech_indicator_list],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            # Using Previous State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    + self.data.close.values.tolist()\n",
    "                    + self.previous_state[\n",
    "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
    "                    ]\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[tech].values.tolist()\n",
    "                            for tech in self.tech_indicator_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    + [self.data.close]\n",
    "                    + self.previous_state[\n",
    "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
    "                    ]\n",
    "                    + sum(\n",
    "                        [[self.data[tech]] for tech in self.tech_indicator_list],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "        return state\n",
    "\n",
    "    def _update_state(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # for multiple stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                + self.data.close.values.tolist()\n",
    "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "                + sum(\n",
    "                    [\n",
    "                        self.data[tech].values.tolist()\n",
    "                        for tech in self.tech_indicator_list\n",
    "                    ],\n",
    "                    [],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # for single stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                + [self.data.close]\n",
    "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "                + sum(\n",
    "                    [[self.data[tech]] for tech in self.tech_indicator_list],\n",
    "                    [],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _get_date(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            date = self.data.date.unique()[0]\n",
    "        else:\n",
    "            date = self.data.date\n",
    "        return date\n",
    "\n",
    "    def get_portfolio_df(self):\n",
    "        portfolio_df = pd.DataFrame(self.portfolio_memory)\n",
    "        portfolio_df[\"date\"] = pd.to_datetime(portfolio_df[\"date\"])\n",
    "        portfolio_df.sort_values(\"date\", inplace=True)\n",
    "        return portfolio_df[\n",
    "            [\n",
    "                \"date\",\n",
    "                \"prev_total_asset\",\n",
    "                \"prev_cash\",\n",
    "                \"prev_market_value\",\n",
    "                \"total_asset\",\n",
    "                \"cash\",\n",
    "                \"market_value\",\n",
    "                \"cost\",\n",
    "                \"trades\",\n",
    "                \"reward\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _get_total_asset(self):\n",
    "        \"\"\"\n",
    "        get current total asset value\n",
    "        \"\"\"\n",
    "        return self.state[0] + self._get_market_value()\n",
    "\n",
    "    def _get_market_value(self):\n",
    "        \"\"\"\n",
    "        get current market value\n",
    "        \"\"\"\n",
    "        return sum(\n",
    "            np.array(self.state[1 : (self.stock_dim + 1)])\n",
    "            * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "        )\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        portfolio_df = self.get_portfolio_df()\n",
    "        df_account_value = portfolio_df[[\"date\", \"total_asset\"]].rename(\n",
    "            columns={\"total_asset\": \"account_value\"}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # date and close price length must match actions length\n",
    "            date_list = self.date_memory[:-1]\n",
    "            df_date = pd.DataFrame(date_list)\n",
    "            df_date.columns = [\"date\"]\n",
    "\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame(action_list)\n",
    "            df_actions.columns = self.data.tic.values\n",
    "            df_actions.index = df_date.date\n",
    "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        else:\n",
    "            date_list = self.date_memory[:-1]\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs\n",
    "\n",
    "    def initial_buy_(self):\n",
    "        \"\"\"Initialize the state, already bought some\"\"\"\n",
    "        prices = self.data.close.values.tolist()\n",
    "        # only use half of the initial amount\n",
    "        market_values_each_tic = 0.5 * self.initial_amount // len(prices)\n",
    "        buy_nums_each_tic = [int(market_values_each_tic // p) for p in prices]\n",
    "        if self.hundred_each_trade:\n",
    "            buy_nums_each_tic = buy_nums_each_tic // 100 * 100\n",
    "\n",
    "\n",
    "        buy_amount = sum(np.array(prices) * np.array(buy_nums_each_tic))\n",
    "\n",
    "        state = (\n",
    "            [self.initial_amount - buy_amount]\n",
    "            + prices\n",
    "            + buy_nums_each_tic\n",
    "            + sum(\n",
    "                [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "                [],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d66621-48cf-40ea-b98d-5b262d41fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77550\n",
      "21120\n"
     ]
    }
   ],
   "source": [
    "train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(df, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76538de6-2554-4a7f-b69b-7f1303363465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_data.csv')\n",
    "trade.to_csv('trade_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db88fde3-3088-471d-a275-f30f1c22f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96cf6369-0195-453c-be44-674a48ac5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 100, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":True,\n",
    "    \"hundred_each_trade\":False\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd613e04-ff28-40c4-8eba-fa0fcafdb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vansh\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da8507ba-f46f-43df-bc16-9ad39026c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d88eb5-3fdf-4d97-87e6-6fac63e83859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from stable_baselines3.common.logger import configure\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aaf254-10a4-427b-87d0-a51677ae73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81600ba0-a53e-4def-9010-6fd138f496a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c468e6-ae7d-42a0-af6f-c0a6e7f3d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b36e7bc5-7e93-409f-9573-3c3f01cba845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "# trained_a2c = A2C.load(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6c12f-3a37-4747-9f78-d7354f2f1b8f",
   "metadata": {},
   "source": [
    "## ddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4c07304-d4f5-4d3c-bcc6-3fa329d26c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38a0e099-d3f3-44fa-ad6b-f1af28979171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\n",
    "                \"batch_size\": 256, \n",
    "               \"buffer_size\": 50000, \n",
    "               \"learning_rate\": 0.0005,\n",
    "               \"action_noise\":\"normal\",\n",
    "                }\n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd0ec4e8-5952-41bf-8cfd-e2d13404038e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_ddpg \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ddpg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mddpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m if_using_ddpg \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py:117\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    115\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    116\u001b[0m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    563\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\shimmy\\openai_gym_compatibility.py:251\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[1;32mIn[17], line 173\u001b[0m, in \u001b[0;36mStockTradingEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, actions):\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mday \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3047\u001b[0m, in \u001b[0;36mIndex.unique\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_view()\n\u001b[1;32m-> 3047\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shallow_copy(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[1;34m(values, mask)\u001b[0m\n\u001b[0;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a8f53-446e-4c60-a801-3631aed55ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(\"agent_ddpg\") if if_using_ddpg else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "196ad376",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 10000, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9b2d2ea-1ba4-48d2-a941-2195c6272f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vansh\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60ccef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg=DDPG.load(\"agent_ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46fe2d98-a239-4d34-90e1-6903b2aa81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3\n",
      "day: 703, episode: 3\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 37865865.49\n",
      "total_reward: 37855865.49\n",
      "total_cost: 531796.00\n",
      "total_trades: 500\n",
      "Sharpe: 0.851\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb45fb1a-5d4d-4eba-b2f4-cf2c57a1a51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>3.748960e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>3.748448e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>3.755106e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>3.763293e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>3.786587e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  account_value\n",
       "698 2023-04-21   3.748960e+07\n",
       "699 2023-04-24   3.748448e+07\n",
       "700 2023-04-25   3.755106e+07\n",
       "701 2023-04-26   3.763293e+07\n",
       "702 2023-04-27   3.786587e+07"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_ddpg.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ade81b-7a8d-46e9-b0ff-89d77345cc58",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c3d7ad8-3f7a-4005-a8ed-b33f790255c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c92e1-c3ca-483f-8fe8-c5b555962893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 77           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 26           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.012801195 |\n",
      "-------------------------------------\n",
      "Episode: 3\n",
      "day: 2584, episode: 3\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 220926.77\n",
      "total_reward: 220826.77\n",
      "total_cost: 52131.21\n",
      "total_trades: 7047\n",
      "Sharpe: 0.513\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013154267  |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -1.26        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.422       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0197      |\n",
      "|    reward               | -0.000720717 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0258       |\n",
      "------------------------------------------\n",
      "Episode: 4\n",
      "day: 2584, episode: 4\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 2113630.96\n",
      "total_reward: 2113530.96\n",
      "total_cost: 883538.54\n",
      "total_trades: 9280\n",
      "Sharpe: 0.438\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 74            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.017947394   |\n",
      "|    clip_fraction        | 0.202         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.6         |\n",
      "|    explained_variance   | 0.208         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.445        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.0203       |\n",
      "|    reward               | -0.0009895717 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00482       |\n",
      "-------------------------------------------\n",
      "Episode: 5\n",
      "day: 2584, episode: 5\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 228689.65\n",
      "total_reward: 228589.65\n",
      "total_cost: 87810.97\n",
      "total_trades: 7088\n",
      "Sharpe: 0.594\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 73            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 110           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012325604   |\n",
      "|    clip_fraction        | 0.139         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.7         |\n",
      "|    explained_variance   | 0.0811        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.271         |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00744      |\n",
      "|    reward               | -0.0002680022 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.5           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 73            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.019665968   |\n",
      "|    clip_fraction        | 0.227         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.7         |\n",
      "|    explained_variance   | 0.956         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.411        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0126       |\n",
      "|    reward               | -0.0016599197 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.121         |\n",
      "-------------------------------------------\n",
      "Episode: 6\n",
      "day: 2584, episode: 6\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 5681.20\n",
      "total_reward: 5581.20\n",
      "total_cost: 8644.64\n",
      "total_trades: 6589\n",
      "Sharpe: 0.405\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 72             |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 168            |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.016593536    |\n",
      "|    clip_fraction        | 0.195          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -42.8          |\n",
      "|    explained_variance   | 0.945          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.434         |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.0103        |\n",
      "|    reward               | -0.00034324682 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.0917         |\n",
      "--------------------------------------------\n",
      "Episode: 7\n",
      "day: 2584, episode: 7\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 15349327.07\n",
      "total_reward: 15349227.07\n",
      "total_cost: 563123.57\n",
      "total_trades: 8530\n",
      "Sharpe: 0.456\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 73             |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 196            |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.019018605    |\n",
      "|    clip_fraction        | 0.236          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -42.9          |\n",
      "|    explained_variance   | 0.823          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.441         |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -0.0224        |\n",
      "|    reward               | -2.4598476e-05 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.0292         |\n",
      "--------------------------------------------\n",
      "Episode: 8\n",
      "day: 2584, episode: 8\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 158522.35\n",
      "total_reward: 158422.35\n",
      "total_cost: 54533.58\n",
      "total_trades: 4938\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 73             |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 223            |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.019791309    |\n",
      "|    clip_fraction        | 0.188          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -43            |\n",
      "|    explained_variance   | 0.7            |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.351         |\n",
      "|    n_updates            | 70             |\n",
      "|    policy_gradient_loss | -0.0096        |\n",
      "|    reward               | -0.00029053137 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.384          |\n",
      "--------------------------------------------\n",
      "Episode: 9\n",
      "day: 2584, episode: 9\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 2222823.06\n",
      "total_reward: 2222723.06\n",
      "total_cost: 203127.24\n",
      "total_trades: 7832\n",
      "Sharpe: 0.554\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 73            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 252           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.019495752   |\n",
      "|    clip_fraction        | 0.227         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -43           |\n",
      "|    explained_variance   | 0.952         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.418        |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.009        |\n",
      "|    reward               | -0.0016190087 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.115         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020195201  |\n",
      "|    clip_fraction        | 0.231        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.1        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.398       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00905     |\n",
      "|    reward               | -0.034887977 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0705       |\n",
      "------------------------------------------\n",
      "Episode: 10\n",
      "day: 2584, episode: 10\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 896395.30\n",
      "total_reward: 896295.30\n",
      "total_cost: 188509.23\n",
      "total_trades: 7601\n",
      "Sharpe: 0.430\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 308          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021265142  |\n",
      "|    clip_fraction        | 0.261        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.2        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.421       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0074      |\n",
      "|    reward               | -0.000276104 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0485       |\n",
      "------------------------------------------\n",
      "Episode: 11\n",
      "day: 2584, episode: 11\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 120837.61\n",
      "total_reward: 120737.61\n",
      "total_cost: 21358.08\n",
      "total_trades: 6467\n",
      "Sharpe: 0.390\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 73             |\n",
      "|    iterations           | 12             |\n",
      "|    time_elapsed         | 336            |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.015740147    |\n",
      "|    clip_fraction        | 0.207          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -43.4          |\n",
      "|    explained_variance   | 0.963          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.395         |\n",
      "|    n_updates            | 110            |\n",
      "|    policy_gradient_loss | -0.00853       |\n",
      "|    reward               | -0.00055337884 |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 0.0473         |\n",
      "--------------------------------------------\n",
      "Episode: 12\n",
      "day: 2584, episode: 12\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 11202.10\n",
      "total_reward: 11102.10\n",
      "total_cost: 7702.37\n",
      "total_trades: 6655\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 72             |\n",
      "|    iterations           | 13             |\n",
      "|    time_elapsed         | 364            |\n",
      "|    total_timesteps      | 26624          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.014474896    |\n",
      "|    clip_fraction        | 0.166          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -43.5          |\n",
      "|    explained_variance   | 0.938          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.423         |\n",
      "|    n_updates            | 120            |\n",
      "|    policy_gradient_loss | -0.014         |\n",
      "|    reward               | -0.00043058267 |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 0.0669         |\n",
      "--------------------------------------------\n",
      "Episode: 13\n",
      "day: 2584, episode: 13\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 108649.23\n",
      "total_reward: 108549.23\n",
      "total_cost: 48573.78\n",
      "total_trades: 6687\n",
      "Sharpe: 0.567\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 72            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 393           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.016045798   |\n",
      "|    clip_fraction        | 0.223         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -43.6         |\n",
      "|    explained_variance   | 0.935         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.418        |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00465      |\n",
      "|    reward               | -8.487458e-05 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.0391        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 421          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.018465549  |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.7        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.42        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | -0.011510517 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0323       |\n",
      "------------------------------------------\n",
      "Episode: 14\n",
      "day: 2584, episode: 14\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 37968.06\n",
      "total_reward: 37868.06\n",
      "total_cost: 36385.24\n",
      "total_trades: 5792\n",
      "Sharpe: 0.518\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 72            |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 449           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01479866    |\n",
      "|    clip_fraction        | 0.186         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -43.7         |\n",
      "|    explained_variance   | 0.973         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.443        |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0154       |\n",
      "|    reward               | -0.0039725783 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.0108        |\n",
      "-------------------------------------------\n",
      "Episode: 15\n",
      "day: 2584, episode: 15\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1373464.64\n",
      "total_reward: 1373364.64\n",
      "total_cost: 139268.42\n",
      "total_trades: 7479\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 72            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 477           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01519084    |\n",
      "|    clip_fraction        | 0.161         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -43.7         |\n",
      "|    explained_variance   | 0.947         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.449        |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0153       |\n",
      "|    reward               | -0.0018598796 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.00837       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 16\n",
      "day: 2584, episode: 16\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 15920176.39\n",
      "total_reward: 15920076.39\n",
      "total_cost: 2052230.08\n",
      "total_trades: 11486\n",
      "Sharpe: 0.439\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 72             |\n",
      "|    iterations           | 18             |\n",
      "|    time_elapsed         | 505            |\n",
      "|    total_timesteps      | 36864          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.018419063    |\n",
      "|    clip_fraction        | 0.155          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -43.8          |\n",
      "|    explained_variance   | 0.979          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.445         |\n",
      "|    n_updates            | 170            |\n",
      "|    policy_gradient_loss | -0.00805       |\n",
      "|    reward               | -0.00014046287 |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 0.0169         |\n",
      "--------------------------------------------\n",
      "Episode: 17\n",
      "day: 2584, episode: 17\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 4972510.42\n",
      "total_reward: 4972410.42\n",
      "total_cost: 1072289.36\n",
      "total_trades: 8997\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 73             |\n",
      "|    iterations           | 19             |\n",
      "|    time_elapsed         | 532            |\n",
      "|    total_timesteps      | 38912          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.014616621    |\n",
      "|    clip_fraction        | 0.0541         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -43.8          |\n",
      "|    explained_variance   | 0.248          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.47           |\n",
      "|    n_updates            | 180            |\n",
      "|    policy_gradient_loss | -0.00152       |\n",
      "|    reward               | -0.00093750417 |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 18.5           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 559          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016287085  |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.8        |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    reward               | -0.033669673 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "Episode: 18\n",
      "day: 2584, episode: 18\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1187076.61\n",
      "total_reward: 1186976.61\n",
      "total_cost: 99531.22\n",
      "total_trades: 7267\n",
      "Sharpe: 0.577\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 73            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 588           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.030918323   |\n",
      "|    clip_fraction        | 0.276         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -43.9         |\n",
      "|    explained_variance   | 0.974         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.229        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | 0.000849      |\n",
      "|    reward               | -0.0049163983 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.431         |\n",
      "-------------------------------------------\n",
      "Episode: 19\n",
      "day: 2584, episode: 19\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1000474.18\n",
      "total_reward: 1000374.18\n",
      "total_cost: 135670.58\n",
      "total_trades: 7562\n",
      "Sharpe: 0.485\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 72             |\n",
      "|    iterations           | 22             |\n",
      "|    time_elapsed         | 620            |\n",
      "|    total_timesteps      | 45056          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.012012735    |\n",
      "|    clip_fraction        | 0.189          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -43.9          |\n",
      "|    explained_variance   | 0.939          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.405         |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -0.00308       |\n",
      "|    reward               | -6.5774635e-05 |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 0.223          |\n",
      "--------------------------------------------\n",
      "Episode: 20\n",
      "day: 2584, episode: 20\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1740146.98\n",
      "total_reward: 1740046.98\n",
      "total_cost: 374808.98\n",
      "total_trades: 8446\n",
      "Sharpe: 0.498\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 648          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013381696  |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.349       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00936     |\n",
      "|    reward               | -0.000258488 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.367        |\n",
      "------------------------------------------\n",
      "Episode: 21\n",
      "day: 2584, episode: 21\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 10886444.34\n",
      "total_reward: 10886344.34\n",
      "total_cost: 2541743.07\n",
      "total_trades: 11574\n",
      "Sharpe: 0.390\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 72            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 676           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012647937   |\n",
      "|    clip_fraction        | 0.177         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44           |\n",
      "|    explained_variance   | 0.979         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.305        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.00782      |\n",
      "|    reward               | -9.590505e-05 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.496         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 711          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00867253   |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.03         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | -0.013114327 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 22\n",
      "day: 2584, episode: 22\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 29235.51\n",
      "total_reward: 29135.51\n",
      "total_cost: 28580.80\n",
      "total_trades: 5589\n",
      "Sharpe: 0.472\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 70             |\n",
      "|    iterations           | 26             |\n",
      "|    time_elapsed         | 753            |\n",
      "|    total_timesteps      | 53248          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.010851881    |\n",
      "|    clip_fraction        | 0.156          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -44.1          |\n",
      "|    explained_variance   | 0.964          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.275         |\n",
      "|    n_updates            | 250            |\n",
      "|    policy_gradient_loss | -0.0139        |\n",
      "|    reward               | -0.00020357504 |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 0.271          |\n",
      "--------------------------------------------\n",
      "Episode: 23\n",
      "day: 2584, episode: 23\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1414985.77\n",
      "total_reward: 1414885.77\n",
      "total_cost: 206658.08\n",
      "total_trades: 6677\n",
      "Sharpe: 0.362\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 70            |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 781           |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.016080694   |\n",
      "|    clip_fraction        | 0.234         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.1         |\n",
      "|    explained_variance   | 0.93          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.211        |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.00456      |\n",
      "|    reward               | -0.0008249258 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.867         |\n",
      "-------------------------------------------\n",
      "Episode: 24\n",
      "day: 2584, episode: 24\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 881537.76\n",
      "total_reward: 881437.76\n",
      "total_cost: 419828.46\n",
      "total_trades: 8102\n",
      "Sharpe: 0.551\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 70            |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 809           |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008677989   |\n",
      "|    clip_fraction        | 0.132         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.2         |\n",
      "|    explained_variance   | 0.97          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.221        |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00777      |\n",
      "|    reward               | -4.424707e-05 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.625         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013787321 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.289      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.06956014 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "Episode: 25\n",
      "day: 2584, episode: 25\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 878402.91\n",
      "total_reward: 878302.91\n",
      "total_cost: 204444.15\n",
      "total_trades: 6453\n",
      "Sharpe: 0.501\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 70            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 868           |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011555885   |\n",
      "|    clip_fraction        | 0.135         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.3         |\n",
      "|    explained_variance   | 0.983         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.119        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.0121       |\n",
      "|    reward               | -9.968078e-05 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.447         |\n",
      "-------------------------------------------\n",
      "Episode: 26\n",
      "day: 2584, episode: 26\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 4210562.04\n",
      "total_reward: 4210462.04\n",
      "total_cost: 450611.20\n",
      "total_trades: 6703\n",
      "Sharpe: 0.452\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 70             |\n",
      "|    iterations           | 31             |\n",
      "|    time_elapsed         | 896            |\n",
      "|    total_timesteps      | 63488          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.013896228    |\n",
      "|    clip_fraction        | 0.172          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -44.4          |\n",
      "|    explained_variance   | 0.923          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.339         |\n",
      "|    n_updates            | 300            |\n",
      "|    policy_gradient_loss | -0.00984       |\n",
      "|    reward               | -3.9823153e-05 |\n",
      "|    std                  | 1.07           |\n",
      "|    value_loss           | 0.108          |\n",
      "--------------------------------------------\n",
      "Episode: 27\n",
      "day: 2584, episode: 27\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 186508.83\n",
      "total_reward: 186408.83\n",
      "total_cost: 33881.31\n",
      "total_trades: 6212\n",
      "Sharpe: 0.449\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 70            |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 924           |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012347785   |\n",
      "|    clip_fraction        | 0.122         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.5         |\n",
      "|    explained_variance   | 0.968         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.365        |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.0161       |\n",
      "|    reward               | -3.756529e-05 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.201         |\n",
      "-------------------------------------------\n",
      "Episode: 28\n",
      "day: 2584, episode: 28\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 42451.76\n",
      "total_reward: 42351.76\n",
      "total_cost: 16230.28\n",
      "total_trades: 4999\n",
      "Sharpe: 0.557\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 70            |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 952           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.015760275   |\n",
      "|    clip_fraction        | 0.153         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.6         |\n",
      "|    explained_variance   | 0.944         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.401        |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.00631      |\n",
      "|    reward               | -7.951968e-05 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.227         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 980           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.017162492   |\n",
      "|    clip_fraction        | 0.189         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.7         |\n",
      "|    explained_variance   | 0.941         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.437        |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.0126       |\n",
      "|    reward               | -0.0065130456 |\n",
      "|    std                  | 1.08          |\n",
      "|    value_loss           | 0.149         |\n",
      "-------------------------------------------\n",
      "Episode: 29\n",
      "day: 2584, episode: 29\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 271828.76\n",
      "total_reward: 271728.76\n",
      "total_cost: 18357.18\n",
      "total_trades: 5792\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 1008          |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013275474   |\n",
      "|    clip_fraction        | 0.147         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -44.8         |\n",
      "|    explained_variance   | 0.962         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.42         |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.0119       |\n",
      "|    reward               | -0.0056601577 |\n",
      "|    std                  | 1.08          |\n",
      "|    value_loss           | 0.0448        |\n",
      "-------------------------------------------\n",
      "Episode: 30\n",
      "day: 2584, episode: 30\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 12988409.78\n",
      "total_reward: 12988309.78\n",
      "total_cost: 1368303.64\n",
      "total_trades: 9693\n",
      "Sharpe: 0.464\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 36             |\n",
      "|    time_elapsed         | 1035           |\n",
      "|    total_timesteps      | 73728          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.019789226    |\n",
      "|    clip_fraction        | 0.206          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -44.9          |\n",
      "|    explained_variance   | 0.875          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.432         |\n",
      "|    n_updates            | 350            |\n",
      "|    policy_gradient_loss | -0.00997       |\n",
      "|    reward               | -0.00010331686 |\n",
      "|    std                  | 1.08           |\n",
      "|    value_loss           | 0.056          |\n",
      "--------------------------------------------\n",
      "Episode: 31\n",
      "day: 2584, episode: 31\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 4112684.31\n",
      "total_reward: 4112584.31\n",
      "total_cost: 692626.41\n",
      "total_trades: 7537\n",
      "Sharpe: 0.465\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 1063          |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010195943   |\n",
      "|    clip_fraction        | 0.084         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45           |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00367      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.012        |\n",
      "|    reward               | -6.295058e-05 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 2.95          |\n",
      "-------------------------------------------\n",
      "Episode: 32\n",
      "day: 2584, episode: 32\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 200120.75\n",
      "total_reward: 200020.75\n",
      "total_cost: 33192.46\n",
      "total_trades: 5663\n",
      "Sharpe: 0.487\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 38             |\n",
      "|    time_elapsed         | 1091           |\n",
      "|    total_timesteps      | 77824          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009847757    |\n",
      "|    clip_fraction        | 0.103          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.1          |\n",
      "|    explained_variance   | 0.96           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.145         |\n",
      "|    n_updates            | 370            |\n",
      "|    policy_gradient_loss | -0.0137        |\n",
      "|    reward               | -2.3151459e-05 |\n",
      "|    std                  | 1.09           |\n",
      "|    value_loss           | 0.85           |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 1120          |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012495796   |\n",
      "|    clip_fraction        | 0.131         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45.2         |\n",
      "|    explained_variance   | 0.935         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.275        |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.0151       |\n",
      "|    reward               | -0.0033672545 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 0.955         |\n",
      "-------------------------------------------\n",
      "Episode: 33\n",
      "day: 2584, episode: 33\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 289785.03\n",
      "total_reward: 289685.03\n",
      "total_cost: 11329.29\n",
      "total_trades: 4500\n",
      "Sharpe: 0.442\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1148         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011531927  |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.2        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.244       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    reward               | -0.004675632 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.409        |\n",
      "------------------------------------------\n",
      "Episode: 34\n",
      "day: 2584, episode: 34\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 3303702.74\n",
      "total_reward: 3303602.74\n",
      "total_cost: 548399.90\n",
      "total_trades: 8066\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 41             |\n",
      "|    time_elapsed         | 1176           |\n",
      "|    total_timesteps      | 83968          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.012765536    |\n",
      "|    clip_fraction        | 0.168          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.2          |\n",
      "|    explained_variance   | 0.91           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.437         |\n",
      "|    n_updates            | 400            |\n",
      "|    policy_gradient_loss | -0.0129        |\n",
      "|    reward               | -0.00014355035 |\n",
      "|    std                  | 1.09           |\n",
      "|    value_loss           | 0.105          |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 35\n",
      "day: 2584, episode: 35\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 46829.96\n",
      "total_reward: 46729.96\n",
      "total_cost: 23409.65\n",
      "total_trades: 5632\n",
      "Sharpe: 0.459\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 42             |\n",
      "|    time_elapsed         | 1204           |\n",
      "|    total_timesteps      | 86016          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0104141645   |\n",
      "|    clip_fraction        | 0.115          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.2          |\n",
      "|    explained_variance   | 0.958          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.347         |\n",
      "|    n_updates            | 410            |\n",
      "|    policy_gradient_loss | -0.0139        |\n",
      "|    reward               | -0.00038228836 |\n",
      "|    std                  | 1.09           |\n",
      "|    value_loss           | 0.41           |\n",
      "--------------------------------------------\n",
      "Episode: 36\n",
      "day: 2584, episode: 36\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 7586566.47\n",
      "total_reward: 7586466.47\n",
      "total_cost: 82903.83\n",
      "total_trades: 6729\n",
      "Sharpe: 0.427\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 43             |\n",
      "|    time_elapsed         | 1232           |\n",
      "|    total_timesteps      | 88064          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.011430528    |\n",
      "|    clip_fraction        | 0.144          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.2          |\n",
      "|    explained_variance   | 0.942          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.378         |\n",
      "|    n_updates            | 420            |\n",
      "|    policy_gradient_loss | -0.0133        |\n",
      "|    reward               | -0.00047296545 |\n",
      "|    std                  | 1.09           |\n",
      "|    value_loss           | 0.241          |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 1260          |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012101646   |\n",
      "|    clip_fraction        | 0.143         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45.3         |\n",
      "|    explained_variance   | 0.954         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.418        |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.0131       |\n",
      "|    reward               | -0.0049701263 |\n",
      "|    std                  | 1.1           |\n",
      "|    value_loss           | 0.249         |\n",
      "-------------------------------------------\n",
      "Episode: 37\n",
      "day: 2584, episode: 37\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 200461.20\n",
      "total_reward: 200361.20\n",
      "total_cost: 25063.61\n",
      "total_trades: 6150\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 45             |\n",
      "|    time_elapsed         | 1288           |\n",
      "|    total_timesteps      | 92160          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.015756354    |\n",
      "|    clip_fraction        | 0.168          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.4          |\n",
      "|    explained_variance   | 0.97           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.424         |\n",
      "|    n_updates            | 440            |\n",
      "|    policy_gradient_loss | -0.0107        |\n",
      "|    reward               | -0.00012350916 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 0.0589         |\n",
      "--------------------------------------------\n",
      "Episode: 38\n",
      "day: 2584, episode: 38\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 13751277.97\n",
      "total_reward: 13751177.97\n",
      "total_cost: 2169032.22\n",
      "total_trades: 9882\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 1317          |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012642765   |\n",
      "|    clip_fraction        | 0.152         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45.5         |\n",
      "|    explained_variance   | 0.937         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.455        |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.0117       |\n",
      "|    reward               | -0.0005101822 |\n",
      "|    std                  | 1.1           |\n",
      "|    value_loss           | 0.0573        |\n",
      "-------------------------------------------\n",
      "Episode: 39\n",
      "day: 2584, episode: 39\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 9043617.39\n",
      "total_reward: 9043517.39\n",
      "total_cost: 1427700.56\n",
      "total_trades: 9211\n",
      "Sharpe: 0.397\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 47             |\n",
      "|    time_elapsed         | 1345           |\n",
      "|    total_timesteps      | 96256          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.015630186    |\n",
      "|    clip_fraction        | 0.0679         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.5          |\n",
      "|    explained_variance   | 0.449          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.4            |\n",
      "|    n_updates            | 460            |\n",
      "|    policy_gradient_loss | -0.00798       |\n",
      "|    reward               | -0.00017014428 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 15.5           |\n",
      "--------------------------------------------\n",
      "Episode: 40\n",
      "day: 2584, episode: 40\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 430674.98\n",
      "total_reward: 430574.98\n",
      "total_cost: 366582.47\n",
      "total_trades: 7301\n",
      "Sharpe: 0.461\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 48             |\n",
      "|    time_elapsed         | 1373           |\n",
      "|    total_timesteps      | 98304          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.008669027    |\n",
      "|    clip_fraction        | 0.0605         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.6          |\n",
      "|    explained_variance   | 0.919          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 0.896          |\n",
      "|    n_updates            | 470            |\n",
      "|    policy_gradient_loss | -0.0111        |\n",
      "|    reward               | -0.00018499544 |\n",
      "|    std                  | 1.11           |\n",
      "|    value_loss           | 7.64           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 1401         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011525154  |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.6        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0355       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | -0.005845419 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 41\n",
      "day: 2584, episode: 41\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 42400.00\n",
      "total_reward: 42300.00\n",
      "total_cost: 16291.98\n",
      "total_trades: 5922\n",
      "Sharpe: 0.544\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 50             |\n",
      "|    time_elapsed         | 1428           |\n",
      "|    total_timesteps      | 102400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.015066218    |\n",
      "|    clip_fraction        | 0.192          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -45.7          |\n",
      "|    explained_variance   | 0.97           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.163         |\n",
      "|    n_updates            | 490            |\n",
      "|    policy_gradient_loss | -0.0145        |\n",
      "|    reward               | -0.00015870566 |\n",
      "|    std                  | 1.11           |\n",
      "|    value_loss           | 0.631          |\n",
      "--------------------------------------------\n",
      "Episode: 42\n",
      "day: 2584, episode: 42\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 167279.14\n",
      "total_reward: 167179.14\n",
      "total_cost: 69818.57\n",
      "total_trades: 5955\n",
      "Sharpe: 0.503\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 1457          |\n",
      "|    total_timesteps      | 104448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013803597   |\n",
      "|    clip_fraction        | 0.131         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45.8         |\n",
      "|    explained_variance   | 0.931         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.00583      |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | -0.0129       |\n",
      "|    reward               | -8.402189e-05 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 1.25          |\n",
      "-------------------------------------------\n",
      "Episode: 43\n",
      "day: 2584, episode: 43\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 165141.60\n",
      "total_reward: 165041.60\n",
      "total_cost: 49886.70\n",
      "total_trades: 6175\n",
      "Sharpe: 0.530\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 1485          |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.015165297   |\n",
      "|    clip_fraction        | 0.137         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45.8         |\n",
      "|    explained_variance   | 0.946         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.22         |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.00907      |\n",
      "|    reward               | -0.0004602528 |\n",
      "|    std                  | 1.12          |\n",
      "|    value_loss           | 0.703         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 1513         |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014032906  |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.9        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.446       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.015863268 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.461        |\n",
      "------------------------------------------\n",
      "Episode: 44\n",
      "day: 2584, episode: 44\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 321384.45\n",
      "total_reward: 321284.45\n",
      "total_cost: 52337.79\n",
      "total_trades: 6163\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1541        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011604223 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.427      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.10643863 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "Episode: 45\n",
      "day: 2584, episode: 45\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 720579.50\n",
      "total_reward: 720479.50\n",
      "total_cost: 220312.99\n",
      "total_trades: 6726\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 55             |\n",
      "|    time_elapsed         | 1569           |\n",
      "|    total_timesteps      | 112640         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.015747374    |\n",
      "|    clip_fraction        | 0.195          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -46.1          |\n",
      "|    explained_variance   | 0.969          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.451         |\n",
      "|    n_updates            | 540            |\n",
      "|    policy_gradient_loss | -0.019         |\n",
      "|    reward               | -0.00093778333 |\n",
      "|    std                  | 1.13           |\n",
      "|    value_loss           | 0.0863         |\n",
      "--------------------------------------------\n",
      "Episode: 46\n",
      "day: 2584, episode: 46\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1009968.54\n",
      "total_reward: 1009868.54\n",
      "total_cost: 298710.17\n",
      "total_trades: 7249\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 1597          |\n",
      "|    total_timesteps      | 114688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013469463   |\n",
      "|    clip_fraction        | 0.146         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.1         |\n",
      "|    explained_variance   | 0.988         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.41         |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -0.00932      |\n",
      "|    reward               | -0.0017598283 |\n",
      "|    std                  | 1.13          |\n",
      "|    value_loss           | 0.144         |\n",
      "-------------------------------------------\n",
      "Episode: 47\n",
      "day: 2584, episode: 47\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 11647806.24\n",
      "total_reward: 11647706.24\n",
      "total_cost: 1569654.37\n",
      "total_trades: 9384\n",
      "Sharpe: 0.549\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 57            |\n",
      "|    time_elapsed         | 1626          |\n",
      "|    total_timesteps      | 116736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011982571   |\n",
      "|    clip_fraction        | 0.141         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.2         |\n",
      "|    explained_variance   | 0.975         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.363        |\n",
      "|    n_updates            | 560           |\n",
      "|    policy_gradient_loss | -0.0105       |\n",
      "|    reward               | -0.0008119181 |\n",
      "|    std                  | 1.13          |\n",
      "|    value_loss           | 0.286         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1654         |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071790265 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.2        |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.557        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -0.005816503 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 5.55         |\n",
      "------------------------------------------\n",
      "Episode: 48\n",
      "day: 2584, episode: 48\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1435262.55\n",
      "total_reward: 1435162.55\n",
      "total_cost: 28173.25\n",
      "total_trades: 5775\n",
      "Sharpe: 0.355\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 1683          |\n",
      "|    total_timesteps      | 120832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0120327175  |\n",
      "|    clip_fraction        | 0.11          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.3         |\n",
      "|    explained_variance   | 0.949         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.116        |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.00993      |\n",
      "|    reward               | -0.0003549373 |\n",
      "|    std                  | 1.13          |\n",
      "|    value_loss           | 0.818         |\n",
      "-------------------------------------------\n",
      "Episode: 49\n",
      "day: 2584, episode: 49\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 2118051.56\n",
      "total_reward: 2117951.56\n",
      "total_cost: 424395.54\n",
      "total_trades: 7162\n",
      "Sharpe: 0.424\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 60             |\n",
      "|    time_elapsed         | 1711           |\n",
      "|    total_timesteps      | 122880         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.013745824    |\n",
      "|    clip_fraction        | 0.171          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -46.4          |\n",
      "|    explained_variance   | 0.838          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.41          |\n",
      "|    n_updates            | 590            |\n",
      "|    policy_gradient_loss | -0.0134        |\n",
      "|    reward               | -0.00031545575 |\n",
      "|    std                  | 1.14           |\n",
      "|    value_loss           | 0.235          |\n",
      "--------------------------------------------\n",
      "Episode: 50\n",
      "day: 2584, episode: 50\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 12344351.14\n",
      "total_reward: 12344251.14\n",
      "total_cost: 1764306.78\n",
      "total_trades: 9507\n",
      "Sharpe: 0.543\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 1739          |\n",
      "|    total_timesteps      | 124928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010389219   |\n",
      "|    clip_fraction        | 0.111         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.4         |\n",
      "|    explained_variance   | 0.978         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.341        |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | -0.0125       |\n",
      "|    reward               | -5.065365e-05 |\n",
      "|    std                  | 1.14          |\n",
      "|    value_loss           | 0.352         |\n",
      "-------------------------------------------\n",
      "Episode: 51\n",
      "day: 2584, episode: 51\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 692398.67\n",
      "total_reward: 692298.67\n",
      "total_cost: 130069.66\n",
      "total_trades: 5189\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 1767         |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008987926  |\n",
      "|    clip_fraction        | 0.0756       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.5        |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | -0.000308456 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 6.54         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1795        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011911873 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0971     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.06302291 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.978       |\n",
      "-----------------------------------------\n",
      "Episode: 52\n",
      "day: 2584, episode: 52\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 770076.89\n",
      "total_reward: 769976.89\n",
      "total_cost: 145928.81\n",
      "total_trades: 6465\n",
      "Sharpe: 0.521\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 1823          |\n",
      "|    total_timesteps      | 131072        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011881933   |\n",
      "|    clip_fraction        | 0.139         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.5         |\n",
      "|    explained_variance   | 0.978         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.121        |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | -0.0089       |\n",
      "|    reward               | -4.341142e-05 |\n",
      "|    std                  | 1.14          |\n",
      "|    value_loss           | 0.319         |\n",
      "-------------------------------------------\n",
      "Episode: 53\n",
      "day: 2584, episode: 53\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 964297.00\n",
      "total_reward: 964197.00\n",
      "total_cost: 38951.79\n",
      "total_trades: 4022\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 65             |\n",
      "|    time_elapsed         | 1851           |\n",
      "|    total_timesteps      | 133120         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.013452904    |\n",
      "|    clip_fraction        | 0.151          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -46.6          |\n",
      "|    explained_variance   | 0.93           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.296         |\n",
      "|    n_updates            | 640            |\n",
      "|    policy_gradient_loss | -0.0112        |\n",
      "|    reward               | -0.00012614817 |\n",
      "|    std                  | 1.15           |\n",
      "|    value_loss           | 0.373          |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 54\n",
      "day: 2584, episode: 54\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1333432.42\n",
      "total_reward: 1333332.42\n",
      "total_cost: 92952.96\n",
      "total_trades: 5867\n",
      "Sharpe: 0.432\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 71             |\n",
      "|    iterations           | 66             |\n",
      "|    time_elapsed         | 1879           |\n",
      "|    total_timesteps      | 135168         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.010111347    |\n",
      "|    clip_fraction        | 0.11           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -46.6          |\n",
      "|    explained_variance   | 0.944          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.441         |\n",
      "|    n_updates            | 650            |\n",
      "|    policy_gradient_loss | -0.011         |\n",
      "|    reward               | -0.00065063185 |\n",
      "|    std                  | 1.15           |\n",
      "|    value_loss           | 0.435          |\n",
      "--------------------------------------------\n",
      "Episode: 55\n",
      "day: 2584, episode: 55\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1147147.71\n",
      "total_reward: 1147047.71\n",
      "total_cost: 97798.51\n",
      "total_trades: 6602\n",
      "Sharpe: 0.370\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 71            |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 1907          |\n",
      "|    total_timesteps      | 137216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011998254   |\n",
      "|    clip_fraction        | 0.13          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.7         |\n",
      "|    explained_variance   | 0.955         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.318        |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | -0.0125       |\n",
      "|    reward               | -7.900972e-05 |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 0.385         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 1935         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011509688  |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.8        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.345       |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    reward               | -0.081578255 |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 0.29         |\n",
      "------------------------------------------\n",
      "Episode: 56\n",
      "day: 2584, episode: 56\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 683764.42\n",
      "total_reward: 683664.42\n",
      "total_cost: 301318.36\n",
      "total_trades: 6234\n",
      "Sharpe: 0.479\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1963        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012119483 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.442      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -0.00262383 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.099       |\n",
      "-----------------------------------------\n",
      "Episode: 57\n",
      "day: 2584, episode: 57\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 6266912.54\n",
      "total_reward: 6266812.54\n",
      "total_cost: 546007.08\n",
      "total_trades: 8095\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1990        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015045355 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.00051539 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "Episode: 58\n",
      "day: 2584, episode: 58\n",
      "begin_total_asset: 100.00\n",
      "end_total_asset: 1709857.05\n",
      "total_reward: 1709757.05\n",
      "total_cost: 386315.36\n",
      "total_trades: 7512\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 72             |\n",
      "|    iterations           | 71             |\n",
      "|    time_elapsed         | 2018           |\n",
      "|    total_timesteps      | 145408         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009224154    |\n",
      "|    clip_fraction        | 0.0938         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -47            |\n",
      "|    explained_variance   | 0.958          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.411         |\n",
      "|    n_updates            | 700            |\n",
      "|    policy_gradient_loss | -0.0118        |\n",
      "|    reward               | -7.1984045e-06 |\n",
      "|    std                  | 1.16           |\n",
      "|    value_loss           | 0.455          |\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=200000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea32c67-189d-4329-819a-24a90905f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404851cc-36b4-4cad-b7e2-f321681ef792",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5b890-5bf3-43b3-8d2d-62d97b3efee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467532b6-a48d-47cb-a7ad-b25fac83b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8edcb-a208-42f2-b146-b15c07e8c209",
   "metadata": {},
   "source": [
    "## TD3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182c823-3981-4e10-91e1-02cd7251d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d7981-c04f-4b12-996b-8bf3bb8912ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446516c-b19c-4ad2-b898-ace8d31f53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a00df-9a1f-46e6-a236-4b64f76a9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f389d17-f992-4ac6-8435-5e047579ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0a08d-109d-44b5-95c4-5b1c6c9d48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b9389-4624-464e-9ddd-92eaf400b2f0",
   "metadata": {},
   "source": [
    "## SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57d5a4-dcf7-44d6-9ccb-3bb5e57b19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af8a24-8733-4a73-b0ed-3ec53eb2ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=70000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ba3a7-e5d2-41d9-ae4a-56713f95ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b2e0a-a1a6-45c1-ba6d-de77c45b88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3082be5-5cb8-41a6-a885-72f298037ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb0ace-15c5-41ac-aa01-e9a1deb4ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f12d9-a8fb-4907-838c-9b72fef5992b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
